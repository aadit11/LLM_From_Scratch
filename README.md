ðŸ“Œ Overview
This project implements a Transformer-based neural network from scratch to generate text. The model is inspired by the Transformer architecture introduced in the paper "Attention is All You Need". The goal is to train a language model capable of generating coherent and meaningful text given a seed prompt.
